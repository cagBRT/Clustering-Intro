{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C1: Intro to K-Means Clustering.ipynb ",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNeajNrhkPqEUSzdw7G6r/7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Clustering-Intro/blob/master/C1_Intro_to_K_Means_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYqZIB-LWScz"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/Clustering-Intro.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyQlC0PMUogW"
      },
      "source": [
        "# **Intro to K-Means Clustering**\n",
        "\n",
        "Clustering is a type of machine learning known as **unsupervised**. This means the data does not have labels. Instead of assigning classes to the data, the algorithm does this for us. <br><br>\n",
        "In this notebook you use K-Means Clusteirng. <br>\n",
        "It is very easy to implement and is computationally efficient, which may explain its popularity.<br>\n",
        "K-Means is particularly good at spherical clusters.<br>\n",
        "A weakness of K-Means is it requires you to set the number of clusters before running the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZxqRXRmlDjJ"
      },
      "source": [
        "The k-means algorithm belongs to the category of **prototype-based clustering**.<br>\n",
        "Prototype-based clustering means that each cluster is represented by a prototype, which can either be the:<br>\n",
        ">**centroid** (average) of similar points with continuous features<br>\n",
        ">**medoid** (the most representative or most frequently occurring point) in the case of categorical features.<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGc67lMgfUT1"
      },
      "source": [
        "For example:\n",
        "We have a small data set, shown as page(1).<br>\n",
        "We can divide the data into a number of different clusters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-jMQBvPVFv2"
      },
      "source": [
        "To determine the category for each data point, we allow the algorithm to find groups (or clusters) of similiar data.  \n",
        "\n",
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering1.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering2.png?raw=1)"
      ],
      "metadata": {
        "id": "6c2Wntwks99S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering3.png?raw=1)"
      ],
      "metadata": {
        "id": "eFiw6XgytBDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering4.png?raw=1)"
      ],
      "metadata": {
        "id": "NOQqCobrtFqW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp-_1mEugO9a"
      },
      "source": [
        "**Import the libraries**\n",
        "\n",
        "sklearn has a number of functions for creating test datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTWJ4MX3gN0K"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1_Vlt17gfgy"
      },
      "source": [
        "**Ceate a dataset**<br>\n",
        "Create a dataset for experimeting with clustering.<br>\n",
        "In this example, the data is clustered into three groups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuLXv7wWgfJd"
      },
      "source": [
        "# create dataset\n",
        "X, y = make_blobs(\n",
        "   n_samples=1500, n_features=6,\n",
        "   centers=5, cluster_std=0.5,\n",
        "   shuffle=True, random_state=0\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g37j3VhMgraF"
      },
      "source": [
        "**Plot the dataset**<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LI3KmWgTw2y"
      },
      "source": [
        "# plot\n",
        "plt.scatter(\n",
        "   X[:, 0], X[:, 1],\n",
        "   c='blue', marker='o',\n",
        "   edgecolor='black', s=50\n",
        ")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLkLBWFjoMuU"
      },
      "source": [
        "**The K-Means algorithm**<br>\n",
        "1. Randomly pick k centroids from the sample points as initial cluster centers.\n",
        "2. Assign each sample to the nearest centroid μ^(j), j ∈ {1, …, k}.\n",
        "3. Move the centroids to the center of the samples that were assigned to it.\n",
        "4. Repeat steps 2 and 3 until the cluster assignments do not change or a user-defined tolerance or maximum number of iterations is reached."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcUR_4hwqxUV"
      },
      "source": [
        "The following images are from a [video on K-Means Clustering](https://www.youtube.com/watch?v=4b5d3muPQmA))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbDcd1Gkxoh-"
      },
      "source": [
        "To illustrate the K-Means algorithm, create a small dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering5.png?raw=1)\n",
        "\n",
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering6.png?raw=1)\n",
        "\n",
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering7.png?raw=1)"
      ],
      "metadata": {
        "id": "r5OVs3x8tNwD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXGQLIqQxnbv"
      },
      "source": [
        "This dataset will be grouped into 3 clusters. <br>\n",
        "Randomly choose 3 data points.\n",
        "\n",
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering6.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7qdZEKkyHux"
      },
      "source": [
        "These data points are the initial clusters.\n",
        "\n",
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering7.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElVHffNNyPzT"
      },
      "source": [
        "Measure the distance from each data point to each cluster.\n",
        "\n",
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering8.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuIPCQ1RyZYj"
      },
      "source": [
        "Assign each data point to the closest cluster.\n",
        "\n",
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering9.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52YkHGdlygR-"
      },
      "source": [
        "Each data point is assigned to the closest cluster\n",
        "\n",
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering10.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ay-_lN2yoHk"
      },
      "source": [
        "Calculate the mean of each cluster\n",
        "\n",
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering11.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atTwf3N8yudh"
      },
      "source": [
        "Now, measure each data point from the mean of each cluster. <br>\n",
        "Change the cluster if a data point is closer to that cluster's mean.\n",
        "\n",
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering12.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfswFFfjy2nA"
      },
      "source": [
        "Once there are no more changes, the iteration is done.\n",
        "\n",
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering13.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cLOhCLnzUQV"
      },
      "source": [
        "The first iteration will most likely not produce a very good clustering.\n",
        "\n",
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering14.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBhBIdfvzcvO"
      },
      "source": [
        "Record the variation within each cluster.\n",
        "\n",
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering15.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1x2qWeezmx8"
      },
      "source": [
        "Begin a new iteration, select three new data points as the 3 clusters.\n",
        "\n",
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering17.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMevp_Hjz1Jp"
      },
      "source": [
        "Assign each data point to a cluster. <br>\n",
        "Record the variation in each cluster.<br>\n",
        "The algorithm will select the clustering that produces the least variation between the clusters.\n",
        "\n",
        "![picture](https://github.com/cagBRT/Clustering-Intro/blob/master/images/Clustering18.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj5DO7cHg9nY"
      },
      "source": [
        "**Use the KMeans function**<br>\n",
        "Use the KMeans function to cluster the data. <br><br>\n",
        "Note: you must specify the number of clusters you want.<br>\n",
        "Specify the number of iterations you want.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXMdaQgcGzV5"
      },
      "source": [
        "**Early Stopping**<br>\n",
        "Note: the k-means implementation in scikit-learn stops early if it converges before the maximum number of iterations is reached. <br>\n",
        "\n",
        "However, it is possible that k-means does not reach convergence for a particular run, which can be problematic (computationally expensive) if we choose relatively large values for max_iter.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH8iEuPRHCE-"
      },
      "source": [
        "One way to deal with convergence problems is to choose larger values for tol<br><br>\n",
        "It is the parameter that controls the tolerance with regard to the changes in the within-cluster sum-squared-error to declare convergence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHwvnUMwHURk"
      },
      "source": [
        "**Dealing with Empty Clusters**<br>\n",
        "\n",
        "A problem with k-means is that one or more clusters can be empty. However, this problem is accounted for in the current k-means implementation in scikit-learn. If a cluster is empty, the algorithm will search for the sample that is farthest away from the centroid of the empty cluster. Then it will reassign the centroid to be this farthest point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK-RQsAMT84i"
      },
      "source": [
        "km = KMeans(\n",
        "    n_clusters=5, init='random',\n",
        "    n_init=10, max_iter=300,\n",
        "    tol=1e-04, random_state=0\n",
        ")\n",
        "y_km = km.fit_predict(X)\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1bOFqu20rzc"
      },
      "source": [
        "Plot the dataset and show the centroids for each cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIGpX0v7UBkA"
      },
      "source": [
        "# plot the 3 clusters\n",
        "plt.scatter(\n",
        "    X[y_km == 0, 0], X[y_km == 0, 1],\n",
        "    s=50, c='lightgreen',\n",
        "    marker='s', edgecolor='black',\n",
        "    label='cluster 1'\n",
        ")\n",
        "\n",
        "plt.scatter(\n",
        "    X[y_km == 1, 0], X[y_km == 1, 1],\n",
        "    s=50, c='orange',\n",
        "    marker='o', edgecolor='black',\n",
        "    label='cluster 2'\n",
        ")\n",
        "\n",
        "plt.scatter(\n",
        "    X[y_km == 2, 0], X[y_km == 2, 1],\n",
        "    s=50, c='lightblue',\n",
        "    marker='v', edgecolor='black',\n",
        "    label='cluster 3'\n",
        ")\n",
        "\n",
        "# plot the centroids\n",
        "plt.scatter(\n",
        "    km.cluster_centers_[:, 0], km.cluster_centers_[:, 1],\n",
        "    s=250, marker='*',\n",
        "    c='red', edgecolor='black',\n",
        "    label='centroids'\n",
        ")\n",
        "plt.legend(scatterpoints=1)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ixcn37dnraX"
      },
      "source": [
        "# **Determing the number of clusters to specify**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-WnG8E8UIOS"
      },
      "source": [
        "**Elbow Method**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugw9M8PMHvvu"
      },
      "source": [
        "The elbow method is a useful graphical tool to estimate the optimal number of clusters k for a given task.<br><br>\n",
        "If k (the number of clusters) increases, the within-cluster SSE (“distortion”) will decrease. This is because the samples will be closer to the centroids they are assigned to.<br><br>\n",
        "The idea behind the elbow method is to identify the value of k where the distortion begins to decrease most rapidly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWH6BBIab9wt"
      },
      "source": [
        "# calculate distortion for a range of number of cluster\n",
        "distortions = []\n",
        "for i in range(1, 11):\n",
        "    km = KMeans(\n",
        "        n_clusters=i, init='random',\n",
        "        n_init=10, max_iter=300,\n",
        "        tol=1e-04, random_state=0\n",
        "    )\n",
        "    km.fit(X)\n",
        "    distortions.append(km.inertia_)\n",
        "\n",
        "# plot\n",
        "plt.plot(range(1, 11), distortions, marker='o')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Distortion')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Nghm4y8KId_"
      },
      "source": [
        "# **Assignment**<br>\n",
        "\n",
        "1. Generate a new dataset with:<br>\n",
        "> at least 1500 points. <br>\n",
        "> at least 5 clusters.<br>\n",
        "\n",
        "<br>\n",
        "2. Use the elbow method to see if the recommended number of clusters matches what you selected. <br>\n",
        "3. Execute the KMeans function with your new dataset. <br>\n",
        "4. Can you improve the clustering by changing the paramteters in the KMeans function? <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8lmWHesbr4U"
      },
      "source": [
        "# create dataset\n",
        "X, y = make_blobs(\n",
        "   n_samples=1500, n_features=6,\n",
        "   centers=5, cluster_std=0.9,\n",
        "   shuffle=True, random_state=0\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swRV8mL-b2Hf"
      },
      "source": [
        "# plot\n",
        "plt.scatter(\n",
        "   X[:, 0], X[:, 1],\n",
        "   c='blue', marker='o',\n",
        "   edgecolor='black', s=50\n",
        ")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5BUUGdJUJ7Z"
      },
      "source": [
        "# calculate distortion for a range of number of cluster\n",
        "max_of_clusters = 11\n",
        "distortions = []\n",
        "for i in range(1, max_of_clusters):\n",
        "    km = KMeans(\n",
        "        n_clusters=i, init='random',\n",
        "        n_init=10, max_iter=300,\n",
        "        tol=1e-04, random_state=0\n",
        "    )\n",
        "    km.fit(X)\n",
        "    distortions.append(km.inertia_)\n",
        "\n",
        "# plot\n",
        "plt.plot(range(1, max_of_clusters), distortions, marker='o')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Distortion')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}